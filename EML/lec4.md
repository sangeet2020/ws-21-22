# Lecture 4

## K-NN
- higher k, more the bias
- kNN is better than linear model
- Linear models: parametric
- KNN
    - adding noise variables upsets KNN
    - in high dimension data points thin out
    - no nearby neighbors

## Classification
- predicts categorical outputs
- optimal calssifier: Bayes classifier
- Binary classification
- Logsitic regression
    - values are forced to map between [0, 1]
- Maximum likelihood
    - rather then minimizing MSE, we maximize likelihood
    - Newton raphson
        - use double derivative to anayze the gradient into taking larger step in the direction of steep.
- discriminative vs Generative classification
- Making predictions

